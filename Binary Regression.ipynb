{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import tensorflow as tf  # Import TensorFlow after Scipy or Scipy will break\n",
    "from PIL import Image\n",
    "from util import *\n",
    "\n",
    "IMAGE_HEIGHT = 227\n",
    "IMAGE_WIDTH = 227\n",
    "COLOR_CHANNELS = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VGG_MODEL = 'imagenet-vgg-verydeep-19.mat'\n",
    "\n",
    "class Weights:\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.weights = {}\n",
    "        graph = kwargs.get('graph', None)\n",
    "        shape = kwargs.get('shape', None)\n",
    "        npzfile = kwargs.get('npzfile', None)\n",
    "        if graph: # initialize by corresponding graph structure\n",
    "            for key, _ in graph.iteritems():\n",
    "                # remove first dim for batch size\n",
    "                weight_shape = graph[key].get_shape()[1:]\n",
    "                self.weights[key+'_w'] = tf.Variable(tf.zeros(weight_shape), name = key+'_w')\n",
    "            self.shape = { key: weight.get_shape() for key, weight in self.weights.iteritems() }\n",
    "        elif shape: # initialize w.r.t shape of existing Weight\n",
    "            for key, s in shape.iteritems():\n",
    "                self.weights[key] = tf.Variable(tf.zeros(s), name = key)\n",
    "            self.shape = shape\n",
    "        else: # initialize from loaded file\n",
    "            for key, value in npzfile.iteritems():\n",
    "                self.weights[key] = tf.Variable(value, name = key)\n",
    "            self.shape = { key: weight.get_shape() for key, weight in self.weights.iteritems() }\n",
    "\n",
    "    def add(self, W): #  NOT inplace sum\n",
    "        Sum = Weights(shape = self.shape)\n",
    "        for key, _ in Sum.weights.iteritems():\n",
    "            Sum.weights[key] = tf.add(self.weights[key], W.weights[key])\n",
    "        return Sum\n",
    "\n",
    "    def sub(self, W):\n",
    "        Sub = Weights(shape = self.shape)\n",
    "        for key, _ in Sub.weights.iteritems():\n",
    "            Sub.weights[key] = tf.sub(self.weights[key], W.weights[key])\n",
    "        return Sub\n",
    "\n",
    "    def sqr_norm(self):\n",
    "        return sum([tf.reduce_sum(tf.square(w)) for _, w in self.weights.iteritems()])\n",
    "\n",
    "    def soft_thresh(self, s):\n",
    "        W = Weights(shape = self.shape)\n",
    "        for key, w in self.weights.iteritems():\n",
    "            W.weights[key] = tf.maximum(tf.abs(w) - s, tf.zeros(w.get_shape()))\n",
    "            W.weights[key] = tf.mul(tf.sign(w), W.weights[key])\n",
    "        return W\n",
    "\n",
    "    def compute_reg(self, graph):\n",
    "\n",
    "        def _inner_prod(t1, t2):\n",
    "            # use broadcast of tf.mul, reduce sum in consistant dim\n",
    "            return tf.reduce_sum(tf.mul(t1,t2), [1, 2, 3])\n",
    "\n",
    "        # sum of inner products of output coeffs and weights\n",
    "        return sum([_inner_prod(weight, graph[key[:-2]]) for key, weight in self.weights.iteritems() ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_graph(image):\n",
    "    graph = load_vgg_model(VGG_MODEL, input_image = image)\n",
    "    model_var = tf.all_variables()\n",
    "\n",
    "    def _normalize_graph(graph):\n",
    "        for key, val in graph.iteritems():\n",
    "            graph[key] = tf.scalar_mul(.1/tf.reduce_mean(val), val)\n",
    "\n",
    "    _normalize_graph(graph)\n",
    "\n",
    "    return (graph, model_var)\n",
    "\n",
    "\n",
    "def reg_loss(regs, labels):\n",
    "    return tf.reduce_mean(tf.squared_difference(regs , labels))\n",
    "\n",
    "def residual_loss(beta, z, u):\n",
    "    return beta.sub(z).add(u).sqr_norm()\n",
    "\n",
    "def start_session(model_var):\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.initialize_variables(model_var))\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    return sess\n",
    "\n",
    "def update_z(z, beta, u, s):\n",
    "    op = []\n",
    "    for key, val in beta.add(u).soft_thresh(s).weights.iteritems():\n",
    "        op.append(z.weights[key].assign(val))\n",
    "    return tf.group(*op)\n",
    "\n",
    "def check(z, beta, u, s):\n",
    "    tmp = beta.add(u).soft_thresh(s)\n",
    "    min_nz = []\n",
    "    for _, val in tmp.weights.iteritems():\n",
    "        min_nz.append( tf.reduce_min(tf.abs(val) + tf.scalar_mul(1,tf.to_float(tf.equal(val, 0))) ) )\n",
    "    return tf.reduce_min(tf.pack(min_nz))\n",
    "\n",
    "def update_u(u, beta, z):\n",
    "    op = []\n",
    "    for key, val in u.add(beta).sub(z).weights.iteritems():\n",
    "        op.append(u.weights[key].assign(val))\n",
    "    return tf.group(*op)\n",
    "\n",
    "def tf_count_zero(t):\n",
    "    elements_equal_to_value = tf.equal(t, 0)\n",
    "    as_ints = tf.cast(tf.equal(t, 0), tf.int32)\n",
    "    count = tf.reduce_sum(as_ints)\n",
    "    return count\n",
    "\n",
    "def load_Weight(filename):\n",
    "    Wfile = np.load(filename)\n",
    "    return Weights(npzfile = Wfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check minimum non-zero value: 1.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Content image to use.\n",
    "CONTENT_IMAGE = 'images/inputs/hummingbird-photo_p1-rot.jpg' #'images/inputs/hummingbird-small.jpg'\n",
    "content_image = load_image(CONTENT_IMAGE, image_width=IMAGE_WIDTH, image_height=IMAGE_HEIGHT)\n",
    "# Style image to use.\n",
    "STYLE_IMAGE = 'images/inputs/Nr2_original_p1-ds.jpg' #'images/inputs/Nr2_orig.jpg'\n",
    "style_image = load_image(STYLE_IMAGE, image_width=IMAGE_WIDTH, image_height=IMAGE_HEIGHT)\n",
    "labels = tf.constant([0 , 1], dtype = 'float32')\n",
    "\n",
    "graph, model_var = build_graph(tf.concat(0, [content_image, style_image]))\n",
    "\n",
    "beta = Weights(graph = graph)\n",
    "regs = beta.compute_reg(graph)\n",
    "\n",
    "z = Weights(graph = graph)\n",
    "u = Weights(graph = graph)\n",
    "\n",
    "loss = reg_loss(regs, labels) + residual_loss(beta, z, u)\n",
    "opt = tf.train.AdamOptimizer(learning_rate=0.0000001)\n",
    "opt_op = opt.minimize(loss, var_list=beta.weights.values())\n",
    "\n",
    "sess = start_session(model_var)\n",
    "itr = 0\n",
    "s = 2e-7\n",
    "loss_bd = 1.0e-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check minimum non-zero value: 1.5632e-13\n"
     ]
    }
   ],
   "source": [
    "opt_op.run()\n",
    "loss_val = sess.run(loss)\n",
    "sess.run(update_z(z, beta, u, s))\n",
    "print(\"check minimum non-zero value: %.4e\" % sess.run(check(z, beta, u, s)))\n",
    "sess.run(update_u(u, beta, z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv5_2_w : 1.0000e+00\n",
      "conv5_2_w : 0.0000e+00\n",
      "conv5_3_w : 1.0000e+00\n",
      "conv5_3_w : 0.0000e+00\n",
      "conv5_1_w : 1.0000e+00\n",
      "conv5_1_w : 0.0000e+00\n",
      "conv1_2_w : 1.0000e+00\n",
      "conv1_2_w : 0.0000e+00\n",
      "conv1_1_w : 1.0000e+00\n",
      "conv1_1_w : 0.0000e+00\n",
      "avgpool2_w : 1.0000e+00\n",
      "avgpool2_w : 0.0000e+00\n",
      "conv4_4_w : 1.0000e+00\n",
      "conv4_4_w : 0.0000e+00\n",
      "conv4_3_w : 1.0000e+00\n",
      "conv4_3_w : 0.0000e+00\n",
      "conv4_2_w : 1.0000e+00\n",
      "conv4_2_w : 0.0000e+00\n",
      "avgpool1_w : 1.0000e+00\n",
      "avgpool1_w : 0.0000e+00\n",
      "conv5_4_w : 1.0000e+00\n",
      "conv5_4_w : 0.0000e+00\n",
      "conv3_1_w : 1.0000e+00\n",
      "conv3_1_w : 0.0000e+00\n",
      "conv2_1_w : 1.0000e+00\n",
      "conv2_1_w : 0.0000e+00\n",
      "conv4_1_w : 1.0000e+00\n",
      "conv4_1_w : 0.0000e+00\n",
      "conv3_2_w : 1.0000e+00\n",
      "conv3_2_w : 0.0000e+00\n",
      "avgpool4_w : 1.0000e+00\n",
      "avgpool4_w : 0.0000e+00\n",
      "conv3_3_w : 1.0000e+00\n",
      "conv3_3_w : 0.0000e+00\n",
      "avgpool5_w : 1.0000e+00\n",
      "avgpool5_w : 0.0000e+00\n",
      "input_w : 9.9476e-14\n",
      "input_w : 1.3480e-10\n",
      "conv2_2_w : 1.0000e+00\n",
      "conv2_2_w : 0.0000e+00\n",
      "conv3_4_w : 1.0000e+00\n",
      "conv3_4_w : 0.0000e+00\n",
      "avgpool3_w : 1.0000e+00\n",
      "avgpool3_w : 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "for key in beta.weights.keys():\n",
    "    tmp = tf.abs(beta.soft_thresh(s).weights[key])\n",
    "    print(\"%s : %.4e\" % (key, tf.reduce_min(tmp + tf.to_float(tf.equal(tmp, 0))).eval()) )\n",
    "    print(\"%s : %.4e\" % (key, tf.reduce_max(tmp).eval()) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npzfile = np.load(\"z_thresh-1.00e-06.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = load_Weight(\"z_thresh-1.00e-06.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Content image to use.\n",
    "CONTENT_IMAGE = 'images/inputs/hummingbird-photo_p1-rot.jpg' #'images/inputs/hummingbird-small.jpg'\n",
    "content_image = load_image(CONTENT_IMAGE, image_width=IMAGE_WIDTH, image_height=IMAGE_HEIGHT)\n",
    "image = tf.squeeze(tf.constant( content_image ))\n",
    "# Style image to use.\n",
    "STYLE_IMAGE = 'images/inputs/Nr2_original_p1-ds.jpg' #'images/inputs/Nr2_orig.jpg'\n",
    "style_image = load_image(STYLE_IMAGE, image_width=IMAGE_WIDTH, image_height=IMAGE_HEIGHT)\n",
    "images = tf.concat(0, [content_image, style_image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Slice_1:0' shape=(100, 100, 3) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf.image.crop_to_bounding_box(image, 0, 0, 200, 200)\n",
    "tf.image.crop_to_bounding_box(tf.image.resize_images(image, 200, 100), 100, 0, 100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
